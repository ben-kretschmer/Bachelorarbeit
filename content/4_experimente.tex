\chapter{Experimente}\label{ch:experimente}
In diesem Kapitel der Arbeit wird der Lösungsansatz getestet, indem Cloud-Computing-Anbieter getestet und die Ergebnisse anschließend eingeordnet werden.
\label{krit-kat-experimente}
\section{Modell-Prüfung}
Die detaillierten Ergebnisse der Prüfung mit dem Formular, das in Microsoft-Excel erstellt wurde, sind im Anhang der Arbeit aufgeführt.
Die Vorgehensweise, die zu diesen Endergebnissen geführt hat, ist in dem vorherigen Kapitel aufgeführt.

\subsection{Einheitliche Gewichtung}
Im Kontext dieser Arbeit wird eine gleiche Gewichtung aller Kriterien im Katalog konfiguriert. Altnativen zu dieser Herangehensweise werden diskutiert.
\begin{figure}
\begin{center}
\includegraphics[width=0.75\linewidth]{figures/Gegen-der-VLI-Bewertungen}
\caption{Resultate im Hinblick auf die Gesamtbewertung}
\label{vendor-lock-in-score}
\end{center}
\end{figure}
\paragraph{Beschreibung der Bewertungen}
Die Abbildung \ref{vendor-lock-in-score} zeigt fünf Säulen in einem Säulendiagramm mit der Überschrift \glq Gegenüberstellung der Vendor-Lock-In-Bewertungen\grq .
An der x-Achse sind die untersuchten Anbieter aufgelistet,
 wobei es sich bei Google Plattform, AWS und Azure um die führenden Anbieter im Cloud-Computing-Bereich handelt.
Die übrigen Anbieter sind IBM und Alibaba, die deutlich kleinere, aber dennoch signifikante Anteile des restlichen Marktes besitzen. 
(vergleiche \ref{lead-cc-A})
An die y-Achse markiert den erreichten Vendor-Lock-In-Score, wobei in dieser Form ein niedriger Score (Bewertung) für ein geringeres Risiko zur Anbieterbindung steht.
Die Anbieter bewegen sich alle im Bereich zwischen 60\% und 80\%, 
wobei die größte Differenz zwischen \glq IBM's Cloud\grq\ und \glq Microsoft's Azure\grq herrscht. 
In diesem Vergleich ist die Bewertung von Microsoft 15\% besser als die Bewertung von IBM.
\paragraph{Beschreibung weiterer Ergebnisse}
Die Abbildung \ref{oss-score} zeigt, wie auch die Gegenüberstellung der Gesamtbewertungen, fünf Säulen und die fünf verglichenen Anbieter.
In dieser Abbildung ist jedoch auf der y-Achse der Anteil der Anwendungen aufgezeichnet, 
die auf der Basis von Open-Source-Technologie gebaut wurden oder selbst als Open-Source-Anwendung vom Cloud-Computing-Anbieter angeboten werden.
Die Anbieter liegen im Bereich zwischen 4\% und 15\%, wobei \glq Google’s Cloud\grq\ 11\% weniger Open-Source-Anwendungen aufweist als \grq Microsoft's Azure\grq .

\begin{figure}
\begin{center}
\includegraphics[width=0.75\linewidth]{figures/Gegen-der-OSS-Scores}
\label{oss-score}
\caption{Ergänzende Ergebnisse im Hinblick auf Open-Source-Nutzung bei den Produkten}
\end{center}
\end{figure}

\section{Interpretation}
\paragraph{Fokus auf die Gesamtbewertung}
Die erzielten Ergebnisse sind sich im Verhältnis zueinander sehr ähnlich, vor allem Google, Alibaba und AWS haben nahezu das gleiche Ergebnis erzielt.

Aufgrund der gesetzlichen Vorgaben für die kubus IT als Dienstleister im öffentlichen Dienst, muss der Anbieter \glq Alibaba Cloud\grq aufgrund des Firmensitzes in China ausgeschlossen werden. Die übrigen Anbieter befinden sich ebenfalls im europäischen Ausland, konkret die Vereinigten Staaten von Amerika. Mit Bezug auf den Abschnitt \ref{geduldete-Länder} ist die Verwendung dieser Anbieter möglich.
An dieser Stelle wird darauf hingewiesen, dass auch der chinesische Anbieter  \glq Alibaba Cloud\grq Standorte in Deutschland hat. Es wird jedoch angenommen, dass bei einer konkreten Entscheidungsfindung dieser Umstand nicht ausreichend ist, um den Anbieter zu wählen.

\subsection{Bedeutung der Ergebnisse}
\paragraph{Niedrigste Anbieterbindung}
Es lässt sich den Ergebnissen entnehmen, dass, auf Basis der angewendeten Methodik, \glq Microsoft's Azure\grq\ die niedrigste Anbieterbindung erzeugt.

Die konkrete Bedeutung der Bewertung muss näher ausgearbeitet werden.
Hierfür wird ein fiktiver Worst-Case-Anbieter, der die Bewertung 100\% bekommt und ein fiktiver Best-Case-Anbieter, der die Bewertung 0\% erhält interpoliert.

Für konkrete Kosten- oder Zeitprognosen könnten die beiden Extremfälle ermittelt werden.
Im Anschluss ließen sich daraus konkrete Werte für die gefunden Ergebnisse errechnen.
Die Umrechnung ist nicht Gegenstand der Arbeit.

Unter der Annahme, dass eine lineare Beziehung zwischen dem Worst- und dem Best-Case besteht und sich die Zwischenwerte durch lineare Interpolation errechnen lassen, sind Aussagen über das Kosten- und Zeitverhältnis zwischen den Anbietern möglich.
Mit dieser Argumentation lässt sich prognostizieren, dass die Migrationskosten von Microsoft zu einem anderen Anbieter rund 15\% vorteilhafter sind als die Kosten, die bei IBM anfallen würden.
Dies steht unter der Annahme, dass das Modell die Realität korrekt abbildet.

Einerseits sind die gezeigten Ergebnisse
\subsection{Aussagekraft des Modells}
Die Ergebnisse fundieren auf der Annahme, dass eine Migration erleichtert wird, 
wenn das Migrationsziel und der -Ursprung die gleiche Technologie für die Anwendungen nutzen.
Des Weiteren wird angenommen, 
dass eine Dokumentation der Architektur und der Schnittstellen einer Anwendung nicht nur die Entwicklung und Arbeit während der Verwendung eines Cloud-Computing-Anbieters erleichtern,
sondern auch bei einer Migration.

In einer Untersuchung zur \glq Vorhersage von Cloud Vendor Lock-In \grq aus dem Jahr 2024 wird die Thematik in feinere Unterpunkte eingeteilt, als im Rahmen dieser Arbeit. In der Untersuchung wir Vendor-Lock-In als Problem beschrieben, dass durch sieben Komponenten bedingt wird:
\begin{itemize}
\item[-] Technischer Lock-In (Datenbank-Lösung, APIs, Service-Funktionen)
\item[-] Daten-bezogener Lock-In (Datenformate und Datenmigration)
\item[-] Service Lock-In (Anbieter-eigene Dienste)
\item[-] Zertifikats Lock-In (Abhängig von Zertifizierungen)
\item[-] Vertraglicher Lock-In (Kündigungsgebühren oder Migrationsgebühren)
\item[-] Wirtschaftlicher Lock-In (Versenkte Kosten in spezielles Training und Geschäftsprozesse)
\item[-] Netzwerk-bezogener Lock-In (Struktur des Netzwerks ist auf einen Anbieter feinjustiert)
\end{itemize}
\parencite[Kap.~2]{math12030387}

In der Arbeit werden neben der Abhängigkeit (Anbieterbindung) auch Kosten verglichen, was nicht Gegenstand dieser Arbeit war.
Die Abhängigkeit jedoch wird in dem Ansatz der Untersuchung mit Formel \ref{different-approach} ermittelt, welche Ähnlichkeiten zu der Formel dieser Arbeit. (vergleiche \ref{Finale-Formel})
\begin{eqnarray}
Dependency Score = \displaystyle\sum_{i=1} ^{n} (w_{i}\cdot f_{i})
\label{different-approach}
\end{eqnarray}
Dabei ist $n$ die Zahl der Faktoren (vergleiche Kriterienkatalog), die berücksichtigt werden. Außerdem ist $w_{i}$ das normalisierte Gewicht des Faktoren (Gewicht eines Kriterium) und $f_{i}$ ist eine normalisierte Bewertung eines Faktors.

Es lässt sich argumentieren, dass die Parallelen zu diesem alternativen Ansatz die grundlegende Methodik dieser Arbeit bestätigen.

\subsection{Diskussion der Methodik}
Bei dieser Herangehensweise werden Punkte wie die finanziellen Möglichkeiten des Unternehmens zum Zeitpunkt der Migration und die geschaffenen Rahmenbedingungen durch organisatorische Punkte wie SLAs ignoriert.

Jene Punkte werden teilweise in anderen Arbeiten aufgenommen. (vergleiche \parencite{math12030387})

Nach der Argumentation der Arbeit wurde dies getan, weil das Thema Anbieterbindung vom Zeitpunkt der Anbieter-Wahl betrachtet werden sollte. 
Die anderen Komponenten der Anbieterbindung werden bei der Gründung einer Beziehung zwischen Cloud-Computing-Anbieter und Kunde relevant und, 
wenn der Wunsch zum Wechsel eines Anbieter feststeht.

Bei der Formel zur Berechnung der Bewertungen wurden außerdem die Einzelbewertungen nicht gleichermaßen normiert wie die Gewichte, was die Errechnung und Handhabung der Ergebnisse vereinfacht hätte. 

\subsection{Überprüfung der Ziele}
Diese Arbeit sollte die Anbieterbindung in einem einfachen Prozess quantifizieren. 
Bei den Untersuchungen wurde mit die Dauer der Bearbeitung jeweils im Bewertungsformular dokumentiert.
Der gesamte Prozess der Ausfüllung mit Hilfe der Tabellenkalkulationssoftware dauerte zwischen zwei und vier Stunden.
